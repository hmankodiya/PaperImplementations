{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import Dinov2Config\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import wandb\n",
    "\n",
    "from dataset import ImageCaptionDataset, Vocab\n",
    "from model import Dinov2Encoder, TextEncoder, ShowAndTell, Model, to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./coco-2014/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "    \n",
    "vocab.size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<dataset.ImageCaptionDataset at 0x70af83d9c730>, 100, 924)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageCaptionDataset(\n",
    "    vocab=vocab,\n",
    "    dataset_path=\"./coco-2014/dataset.json\",\n",
    ")\n",
    "dataset, len(dataset), vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Dinov2Config(patch_size=14)\n",
    "image_encoder = Dinov2Encoder(\n",
    "    config=config, dinov2_weights_path=\"./dinov2-base-weights.pth\", freeze=True\n",
    ")\n",
    "text_encoder = TextEncoder(vocab_size=vocab.size)\n",
    "showtell_core = ShowAndTell(\n",
    "    vocab,\n",
    "    image_encoder,\n",
    "    text_encoder,\n",
    ")\n",
    "showtell_core = to_device(showtell_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "batch = next(iter(dataloader))\n",
    "# image, tokens, others = batch\n",
    "# image, tokens = to_device(image), to_device(tokens)\n",
    "# image.shape, tokens.shape, tokensa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(vocab=vocab, showtell_core=showtell_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhmankodiya\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/harsh/Desktop/Projects/PaperImplementations/ShowAndTell/wandb/run-20241022_013140-59w9urd1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='http://localhost:8080/hmankodiya/ShowAndTell/runs/59w9urd1' target=\"_blank\">full_coverage</a></strong> to <a href='http://localhost:8080/hmankodiya/ShowAndTell' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='http://localhost:8080/hmankodiya/ShowAndTell' target=\"_blank\">http://localhost:8080/hmankodiya/ShowAndTell</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='http://localhost:8080/hmankodiya/ShowAndTell/runs/59w9urd1' target=\"_blank\">http://localhost:8080/hmankodiya/ShowAndTell/runs/59w9urd1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_name = \"ShowAndTell\"\n",
    "run_name = \"full_coverage\"\n",
    "run = wandb.init(name=run_name, project=\"ShowAndTell\")\n",
    "wandb_logger = pl.loggers.WandbLogger(name=run_name, run=run, project=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/harsh/anaconda3/envs/DL/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | showandtell_core | ShowAndTell      | 92.7 M | train\n",
      "1 | criterion        | CrossEntropyLoss | 0      | train\n",
      "--------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "86.6 M    Non-trainable params\n",
      "92.7 M    Total params\n",
      "370.902   Total estimated model params size (MB)\n",
      "243       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/harsh/anaconda3/envs/DL/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc13a4f5ac4f4a46a488312a0792a5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    overfit_batches=0,\n",
    "    max_epochs=10,\n",
    "    logger=[wandb_logger],\n",
    ")\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(showtell_core.state_dict(), f'./weights/{run_name}-{project_name}.pth')\n",
    "model_artifact = wandb.Artifact(name='weights', type='model')\n",
    "model_artifact.add_file(f'./weights/{run_name}-{project_name}.pth')\n",
    "run.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_loss</td><td>3.25975</td></tr><tr><td>trainer/global_step</td><td>999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">full_coverage</strong> at: <a href='http://localhost:8080/hmankodiya/ShowAndTell/runs/59w9urd1' target=\"_blank\">http://localhost:8080/hmankodiya/ShowAndTell/runs/59w9urd1</a><br/> View project at: <a href='http://localhost:8080/hmankodiya/ShowAndTell' target=\"_blank\">http://localhost:8080/hmankodiya/ShowAndTell</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241022_013140-59w9urd1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 480, 640]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "image, tokens, (image_path, image_id) = batch\n",
    "image, tokens = to_device(image), to_device(tokens)\n",
    "image.shape, image.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12, 924]), (12,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showtell_core = to_device(showtell_core)\n",
    "with torch.no_grad():\n",
    "    logits = showtell_core(image, teacher_forcing=False)\n",
    "out_tokens = logits.argmax(-1).detach().cpu().squeeze(0).numpy()\n",
    "logits.shape, out_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0, 154, 521,  78, 521, 289, 803, 389, 101,  22,  97,   1]),\n",
       " tensor([[  0, 154, 521,  78, 521, 289, 803, 389, 101,  22,  97,   1]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tokens, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT <start> closeup of bins of food that include broccoli and bread <end>\n",
      "Pred <start> closeup of bins of food that include broccoli and bread <end>\n"
     ]
    }
   ],
   "source": [
    "print(f'GT {vocab.decode_indexes(tokens.detach().cpu().squeeze(0).numpy())}')\n",
    "print(f'Pred {vocab.decode_indexes(out_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jetliner hillside carryout los scissors savanna include they yellow selfie grass leaves',\n",
       " 'assorted outdoors pomeranian horse clear fry stove lamppost from distance sunny salad',\n",
       " 'cup mostly taxiing backs ramp without fliers graffiti porch door split mostly',\n",
       " 'passenger signs lamps spoon walking coming graffiti knife still <start> tennis their',\n",
       " 'view laptops curve boys ancient living oval pizza soccer filled that hind',\n",
       " 'boats doubles elephant riding loaded groups tiny curious ramp chewing motorcycle bear',\n",
       " 'calves skier seen jumping smaller split neck photo body tips pasta standby',\n",
       " 'soldiers long pictures shoe orange kind laptop video desktop jelly eating traveler',\n",
       " 'canopy boxes fast school make peppers toppings waterfront few peanut bushy runway',\n",
       " 'and pub shows together lots kickstand river stove show horse closeup turned']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.random.randint(low=0, high=924, size=(10, 12))\n",
    "list(map(vocab.decode_indexes, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
