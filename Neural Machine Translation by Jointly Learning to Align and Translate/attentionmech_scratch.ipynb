{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1 = np.array([1, 0, 0])\n",
    "word_2 = np.array([0, 1, 0])\n",
    "word_3 = np.array([1, 1, 0])\n",
    "word_4 = np.array([0, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = np.random.randint(3, size=(3, 3))\n",
    "W_K = np.random.randint(3, size=(3, 3))\n",
    "W_V = np.random.randint(3, size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (3,), (3,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_1 = word_1 @ W_Q\n",
    "key_1 = word_1 @ W_K\n",
    "value_1 = word_1 @ W_V\n",
    " \n",
    "query_2 = word_2 @ W_Q\n",
    "key_2 = word_2 @ W_K\n",
    "value_2 = word_2 @ W_V\n",
    " \n",
    "query_3 = word_3 @ W_Q\n",
    "key_3 = word_3 @ W_K\n",
    "value_3 = word_3 @ W_V\n",
    " \n",
    "query_4 = word_4 @ W_Q\n",
    "key_4 = word_4 @ W_K\n",
    "value_4 = word_4 @ W_V\n",
    "\n",
    "query_1.shape, key_1.shape, value_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.array([np.dot(query_1, key_1), np.dot(query_1, key_2), np.dot(query_1, key_3), np.dot(query_1, key_4)])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = sp.special.softmax(scores / key_1.shape[0] ** 0.5)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import random\n",
    "from numpy import dot\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder representations of four different words\n",
    "word_1 = array([1, 0, 0])\n",
    "word_2 = array([0, 1, 0])\n",
    "word_3 = array([1, 1, 0])\n",
    "word_4 = array([0, 0, 1])\n",
    "word_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking the word embeddings into a single array\n",
    "words = array([word_1, word_2, word_3, word_4])\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating the weight matrices\n",
    "random.seed(42)\n",
    "W_Q = random.randint(3, size=(3, 3))\n",
    "W_K = random.randint(3, size=(3, 3))\n",
    "W_V = random.randint(3, size=(3, 3))\n",
    "W_Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 3), (4, 3), (4, 3))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating the queries, keys and values\n",
    "Q = words @ W_Q\n",
    "K = words @ W_K\n",
    "V = words @ W_V\n",
    "Q.shape, K.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring the query vectors against all key vectors\n",
    "scores = Q @ K.transpose()\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the weights by a softmax operation\n",
    "weights = softmax(scores / K.shape[1] ** 0.5, axis=1)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the attention by a weighted sum of the value vectors\n",
    "attention = weights @ V\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98522025 1.74174051 0.75652026]\n",
      " [0.90965265 1.40965265 0.5       ]\n",
      " [0.99851226 1.75849334 0.75998108]\n",
      " [0.99560386 1.90407309 0.90846923]]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch atteniton mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderSelfAttention(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=256) -> None:\n",
    "        super(EncoderSelfAttention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Q = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
    "        self.K = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
    "        self.V = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_embeddings):\n",
    "        query = self.Q(input_embeddings)\n",
    "        key = self.K(input_embeddings)\n",
    "        value = self.V(input_embeddings)\n",
    "        latent_embeddings = torch.matmul(self.softmax(torch.matmul(query, torch.transpose(key, 0, 1))), value)\n",
    "        return latent_embeddings\n",
    "\n",
    "class DecoderSelfAttention(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=256) -> None:\n",
    "        super(DecoderSelfAttention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Q = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
    "        self.K = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
    "        self.V = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, encoder_embeddings, decoder_embeddings):\n",
    "        query = self.Q(decoder_embeddings)\n",
    "        key = self.K(encoder_embeddings)\n",
    "        value = self.V(encoder_embeddings)\n",
    "        latent_embeddings = torch.matmul(self.softmax(torch.matmul(query, torch.transpose(key, 0, 1))), value)\n",
    "        return latent_embeddings\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder, input_vocab_size, target_vocab_size) -> None:\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder_embeddings = nn.Embedding(input_vocab_size, self.encoder.hidden_size)\n",
    "        self.decoder_embeddings = nn.Embedding(target_vocab_size, self.decoder.hidden_size)\n",
    "        self.output_layer = nn.Linear(in_features=self.decoder.hidden_size, out_features=target_vocab_size)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        input_embeddings, target_embeddings = self.encoder_embeddings(batch[0]), self.decoder_embeddings(batch[1])\n",
    "        encoder_embeddings = self.encoder(input_embeddings)\n",
    "        decoder_embeddings = self.decoder(encoder_embeddings, target_embeddings)\n",
    "        output_probabilities = self.softmax(self.output_layer(decoder_embeddings))\n",
    "        \n",
    "        return output_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = 100\n",
    "target_vocab_size = 200\n",
    "hidden_size = 256\n",
    "\n",
    "encoder = EncoderSelfAttention(input_size=hidden_size, hidden_size=hidden_size)\n",
    "decoder = DecoderSelfAttention(input_size=hidden_size, hidden_size=hidden_size)\n",
    "model = Model(encoder, decoder, input_vocab_size, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([7]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sent = torch.randint(0, high=input_vocab_size, size=(5, ))\n",
    "target_sent = torch.randint(0, high=target_vocab_size, size=(7, ))\n",
    "input_sent.size(), target_sent.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model((input_sent, target_sent)).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer module in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975993/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "from language import prepareData, indexesFromSentence, tensorFromSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer = nn.MultiheadAttention(256, num_heads=2)\n",
    "input_embeddings = torch.rand(10, 256)\n",
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 256]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output, attn_weights = attention_layer(input_embeddings, input_embeddings, input_embeddings)\n",
    "attn_output.shape, attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 135842 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 13043\n",
      "fra 21334\n"
     ]
    }
   ],
   "source": [
    "eng, fra, pairs =  prepareData('eng', 'fra', reverse=False)\n",
    "pairs = np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['go .', 'run !', 'run !', 'wow !', 'fire !'], dtype='<U348')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_sentences= pairs[:, 0]\n",
    "eng_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'sentences': eng_sentences}).drop_duplicates(subset=['sentences'])\n",
    "# df['labels'] = np.random.randint(0, 2, len(df))\n",
    "# df.to_csv('./HappySad.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./HappySad.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['word_array'] = df['sentences'].str.split(' ')\n",
    "# df['lengths'] = df['word_array'].map(len)\n",
    "# # df['indexes'] = df['sentences'].apply(lambda x: indexesFromSentence(lang=eng, sentence=x))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./HappySad.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./HappySad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "      <th>word_array</th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go .</td>\n",
       "      <td>1</td>\n",
       "      <td>['go', '.']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run !</td>\n",
       "      <td>0</td>\n",
       "      <td>['run', '!']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow !</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', '!']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fire !</td>\n",
       "      <td>0</td>\n",
       "      <td>['fire', '!']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help !</td>\n",
       "      <td>0</td>\n",
       "      <td>['help', '!']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentences  labels     word_array  lengths\n",
       "0      go .       1    ['go', '.']        2\n",
       "1     run !       0   ['run', '!']        2\n",
       "2     wow !       0   ['wow', '!']        2\n",
       "3    fire !       0  ['fire', '!']        2\n",
       "4    help !       0  ['help', '!']        2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2, 3]), array([4, 5]), array([6, 5]), array([7, 5]), array([8, 5])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = (df['sentences'].apply(lambda x: np.array(indexesFromSentence(lang=eng, sentence=x))).values).tolist()\n",
    "indexes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(torch.from_numpy(val).view(-1), torch.tensor(label, dtype=torch.float32)) for val, label in zip(indexes, df['labels'].values)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_size, large_size = len(data)-int(len(data)*0.8), int(len(data)*0.8) \n",
    "dataset = torch.utils.data.random_split(data, [small_size, large_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x7f6958fb66a0>,\n",
       " <torch.utils.data.dataset.Subset at 0x7f6958f4d400>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldataloader, largedataloader = torch.utils.data.DataLoader(dataset[0]),torch.utils.data.DataLoader(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "for i in smalldataloader:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13043"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.randint(low=0, high=10, size=(2, 5))\n",
    "emb = torch.nn.Embedding(10, 10)\n",
    "attention = torch.nn.MultiheadAttention(10, 1, batch_first=True)\n",
    "lstm = torch.nn.LSTM(10, 50)\n",
    "linear = torch.nn.Linear(50, 2)\n",
    "emb_bag = torch.nn.EmbeddingBag(10,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_emb = emb(rand)\n",
    "out_multi_head_attention = attention(out_emb, out_emb, out_emb)\n",
    "# # out_lstm = lstm(out_emb)\n",
    "# # out_linear = linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 10]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_multi_head_attention[0].shape, out_multi_head_attention[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_multi_head_attention[0].shape, out_multi_head_attention[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_emb_bag = emb_bag(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_emb_bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_emb.shape, out_lstm[0].shape, out_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_lstm[1][0].shape, out_lstm[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(1 ,256)\n",
    "layer_norm = nn.LayerNorm(256)\n",
    "layer_norm(rand).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(3, 5)\n",
    "m = nn.MaxPool1d(3)\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2461, 0.3953, 0.8410, 0.9194, 0.1892],\n",
       "        [0.5102, 0.0947, 0.4375, 0.5227, 0.8972],\n",
       "        [0.0245, 0.2001, 0.3511, 0.2447, 0.9994]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8410],\n",
       "        [0.5102],\n",
       "        [0.3511]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(3,5)\n",
    "rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6874, 0.8160, 0.5038, 0.5187, 0.9197],\n",
       "        [0.0140, 0.0012, 0.0972, 0.8109, 0.1201],\n",
       "        [0.3666, 0.0658, 0.1525, 0.4796, 0.8438]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6874, 0.8160, 0.5038, 0.8109, 0.9197])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.max(dim=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnModel(pl.LightningModule):\n",
    "    def __init__(self, lang, hidden_size=256):\n",
    "        super(AttnModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(lang.n_words, hidden_size)\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, 1)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.feed_forward = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.loss = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        embeddings = self.embeddings(input) # length, hidden\n",
    "        linear1 = self.relu(self.linear1(embeddings)) # length, hidden \n",
    "        \n",
    "        self.attention_output, self.attention_weights = self.attention(linear1, \n",
    "                                                             linear1, \n",
    "                                                             linear1) # length, hidden\n",
    "        add_and_norm1 = self.layer_norm(self.attention_output+linear1) # length, hidden\n",
    "        \n",
    "        feed_forward = self.relu(self.feed_forward(add_and_norm1)) # length, hidden\n",
    "        add_and_norm2 = self.layer_norm(feed_forward+add_and_norm1) # length, hidden\n",
    "         \n",
    "        # max returns tuple of values and indices, hence we take value.\n",
    "        attention_output_aggregated = self.attention_output.max(dim=0)[0] # length, hidden\n",
    "        feed_forward = self.relu(self.feed_forward(attention_output_aggregated))\n",
    "        linear2 = self.linear2(feed_forward)\n",
    "        return self.sigmoid(linear2)\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        train_loss = torch.as_tensor([i['loss'] for i in outputs]).mean()\n",
    "        self.log_dict({'train_loss_epoch': train_loss})\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_tensor, target_tensor = batch[0][0], batch[1]\n",
    "        \n",
    "        output_tensor = self(input_tensor)\n",
    "        loss = self.loss(output_tensor, target_tensor)\n",
    "        \n",
    "        return {'loss':loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(),\n",
    "                                     lr=0.01)\n",
    "        return optimizer\n",
    "        \n",
    "\n",
    "model = AttnModel(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "\n",
    "batch = next(iter(smalldataloader))\n",
    "X,y = batch[0][0], batch[1]\n",
    "model_out = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5171], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15]), torch.float32, device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.dtype, X.device, model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | embeddings   | Embedding          | 3.3 M \n",
      "1 | linear1      | Linear             | 65.8 K\n",
      "2 | attention    | MultiheadAttention | 263 K \n",
      "3 | layer_norm   | LayerNorm          | 512   \n",
      "4 | feed_forward | Linear             | 65.8 K\n",
      "5 | linear2      | Linear             | 257   \n",
      "6 | sigmoid      | Sigmoid            | 0     \n",
      "7 | relu         | ReLU               | 0     \n",
      "8 | loss         | BCELoss            | 0     \n",
      "----------------------------------------------------\n",
      "3.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.7 M     Total params\n",
      "14.938    Total estimated model params size (MB)\n",
      "/home/harsh/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d1d399c8564b6e8f5417099ad102a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 10:48:02.408607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-01 10:48:07.900713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-01 10:48:07.901181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-01 10:48:07.901192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/harsh/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "tblogger = pl.loggers.TensorBoardLogger('.', version='trial2')\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='gpu', logger=tblogger)\n",
    "trainer.fit(model=model, train_dataloaders=smalldataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cur loss 0.6977843642234802: 100%|██████████| 18705/18705 [00:52<00:00, 358.52it/s]\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "pbar = tqdm.tqdm(smalldataloader, total=len(smalldataloader))\n",
    "for i in pbar:\n",
    "    X, y = i[0][0], i[1]\n",
    "    model_temp_out = model(X)\n",
    "    cur_loss = model.loss(model_out, y)\n",
    "    loss += cur_loss\n",
    "    pbar.set_description(f'cur loss {cur_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6932, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss/len(smalldataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dbf8f4c165eb0b71c72ee397a4a34a0cbf4814bae4fb3ea460f3ccc58581f59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
