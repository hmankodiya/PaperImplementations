dataset_config:
  desc: flicker8k dataset
  train:
    dataset_path: "/home/harsh/Desktop/Projects/PaperImplementations/CLIP/data/train_dataset.json"
    return_dict: true
    padding: longest
    image_size:
      - 224
      - 224
    max_length: 76
    sampling_fn:
      sampling_fn_name: random_sample

  val:
    dataset_path: "/home/harsh/Desktop/Projects/PaperImplementations/CLIP/data/test_dataset.json"
    return_dict: true
    padding: longest
    image_size:
      - 224
      - 224
    max_length: 76
    sampling_fn:
      sampling_fn_name: random_sample

tokenizer_config:
  tokenizer_name: clip-vit-base-patch32
  tokenizer_path: "openai/clip-vit-base-patch32"

model_config:
  clip_model:
    model_name: clip-vit-base-patch32
    model_path: null # "openai/clip-vit-base-patch32"
    config: "default"

trainer_config:
  save_trained_model: true
  # log outputs
  run_name: "clip_first_train"
  output_dir: "/home/harsh/Desktop/Projects/PaperImplementations/CLIP/TrainingLogs"
  overwrite_output_dir: true
  report_to: "tensorboard"
  logging_steps: 30
  logging_strategy: steps
  # train args
  eval_on_start: false
  do_train: true
  # do_eval: true
  # eval_strategy: epocI
  num_train_epochs: 10
  per_device_train_batch_size: 75
  prediction_loss_only: false
  # per_device_eval_batch_size: 45
  # log configs
  # save_steps:
  save_strategy: epoch
  save_total_limit: 3
  remove_unused_columns: false
  save_safetensors: false

  # train configs
  adam_beta1: 0.9
  adam_beta2: 0.98
  adam_epsilon: 1.0E-6
  max_grad_norm: 0.3
  seed: random
  warmup_ratio: 0.05
  learning_rate: 1.0E-5
  lr_scheduler_type: cosine
  optim: "adamw_torch"
  eval_accumulation_steps: 1

  resume_from_checkpoint: null # "/home/harsh/Desktop/Projects/PaperImplementations/ShowAndTell/showandtell_gpt2/TrainingLogs/checkpoint-1800"
