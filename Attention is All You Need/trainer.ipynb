{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "2023-06-30 19:42:10.175831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 19:42:13.052271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-30 19:42:13.052415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-30 19:42:13.052426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import utils as ut\n",
    "from  data import SentenceDataset, Lang, PredictionDataset\n",
    "from model import EncoderLayer, DecoderLayer, Model\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Help!</td>\n",
       "      <td>À l'aide !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input      Target\n",
       "0    Go.        Va !\n",
       "1   Run!     Cours !\n",
       "3   Wow!  Ça alors !\n",
       "4  Fire!    Au feu !\n",
       "5  Help!  À l'aide !"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(f'eng-fra.txt', encoding='utf-8').read().strip().split('\\n')\n",
    "lines = [[s for s in l.split('\\t')] for l in lines]\n",
    "df_lines = pd.DataFrame(columns=['Input', 'Target'], data=lines).drop_duplicates(subset=['Input'])\n",
    "# [-10:].reset_index(drop=True)\n",
    "df_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines['n_words'] = df_lines['Input'].apply(lambda n: len(n.split()))\n",
    "df_lines = df_lines[df_lines['n_words'] >= 10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "max_sequence_length = 70\n",
    "\n",
    "input_emb_size = 512\n",
    "input_num_heads = 8\n",
    "\n",
    "target_emb_size = 512\n",
    "target_num_heads = 8\n",
    "\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input language: English, unique words found 6771\n",
      "target language: French, unique words found 9280\n"
     ]
    }
   ],
   "source": [
    "input_language = Lang('English')\n",
    "target_language = Lang('French')\n",
    "sentencedataset = SentenceDataset(df_lines, input_language, target_language, max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_batch, target_batch = [], []\n",
    "    for input_sentence, target_sentence in batch:\n",
    "        input_batch.append(input_sentence)\n",
    "        target_batch.append(target_sentence)\n",
    "    input_batch = pad_sequence(input_batch, batch_first=True,\n",
    "                               padding_value=input_language.word2index['PAD'])\n",
    "    target_batch = pad_sequence(target_batch, batch_first=True,\n",
    "                                padding_value=target_language.word2index['PAD'])\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dataloader = torch.utils.data.DataLoader(sentencedataset, \n",
    "                                                  batch_size=batch_size,\n",
    "                                                  collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(sentence_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderlayer = EncoderLayer(input_embeddings_size=input_emb_size, input_vocab_size=input_language.n_words,\n",
    "                            num_heads=input_num_heads, max_sequence_length=max_sequence_length)\n",
    "decoderlayer = DecoderLayer(target_embeddings_size=target_emb_size, target_vocab_size=target_language.n_words,\n",
    "                            num_heads=target_num_heads, max_sequence_length=max_sequence_length)\n",
    "model = Model(encoderlayer, decoderlayer, max_sequence_length, input_language, target_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder   | EncoderLayer     | 4.8 M \n",
      "1 | decoder   | DecoderLayer     | 7.1 M \n",
      "2 | linear    | Linear           | 4.8 M \n",
      "3 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "16.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.7 M    Total params\n",
      "66.632    Total estimated model params size (MB)\n",
      "/home/harsh/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1205ab48d194247a80565ccfa8af9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=[0], max_epochs=30)\n",
    "trainer.fit(model, train_dataloaders=sentence_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiondataset = PredictionDataset(sentences=df_lines, input_language=input_language, \n",
    "                                      target_language=target_language, max_sequence_length=max_sequence_length)\n",
    "prediction_dataloader = torch.utils.data.DataLoader(predictiondataset, batch_size=1)\n",
    "pred_batch = next(iter(prediction_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_index(lang, indices):\n",
    "    sentence = ''\n",
    "    for index in indices:\n",
    "        if lang.index2word[index]!='PAD':\n",
    "            sentence += f'{lang.index2word[index]} '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(prediction_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_batch = next(iterator)\n",
    "preds = model.predict_step(pred_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 11), (1, 15))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = pred_batch.detach().cpu().numpy()\n",
    "preds = preds.detach().cpu().numpy()\n",
    "src.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('it is a lot of fun to drive a car EOS ',\n",
       " 'SOS c est tres amusant de conduire une voiture voiture voiture en est rouler EOS ')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_index = 0\n",
    "src_sentence = sentence_from_index(input_language, src[0])\n",
    "preds_sentence = sentence_from_index(target_language, preds[0])\n",
    "src_sentence, preds_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
